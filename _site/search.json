[
  {
    "objectID": "assignment04-tluck15.html",
    "href": "assignment04-tluck15.html",
    "title": "Assignment 04",
    "section": "",
    "text": "np.random.seed(42)\n\npio.renderers.default = \"notebook+notebook_connected+vscode\"\n\n# Initialize Spark Session\nspark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n\n# Load Data\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"data/lightcast_job_postings.csv\")\n\n# Show Schema and Sample Data\n#print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n\n#df.printSchema() # comment this line when rendering the submission\ndf.show(5)\n\nWARNING: Using incubator modules: jdk.incubator.vector\nUsing Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/10/17 03:34:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n25/10/17 03:34:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n[Stage 1:&gt;                                                          (0 + 1) / 1]                                                                                25/10/17 03:34:30 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n[Stage 2:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\nonly showing top 5 rows\n\n\n\n\n\n\n\n\ndf = df.select(\"SALARY\",\"STATE_NAME\",\"NAICS2_NAME\", \"EDUCATION_LEVELS_NAME\", \"MIN_YEARS_EXPERIENCE\", \"DURATION\")\n#df.show()\ndf = df.na.fill({\"MIN_YEARS_EXPERIENCE\": 0, \"DURATION\":0})\n#df.show()\n\n\n\n\n\ndf_pd = df.toPandas()\n#df_pd.head(5)\n(df_pd.isna().sum() / len(df_pd)) * 100\n\n[Stage 3:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\nSALARY                   57.505035\nSTATE_NAME                0.060691\nNAICS2_NAME               0.060691\nEDUCATION_LEVELS_NAME     0.060691\nMIN_YEARS_EXPERIENCE      0.000000\nDURATION                  0.000000\ndtype: float64\n\n\n\n\n\n\nsns.heatmap(df_pd.isna(), cbar=False)\nplt.title(\"Missing Data Heatmap\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\ndf = df.na.drop(subset=[\"SALARY\"])\ndf_pd = df.toPandas()\n\nsns.heatmap(df_pd.isna(), cbar=False)\nplt.title(\"Missing Data Heatmap\")\nplt.show()\n\n[Stage 4:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n\n\n\n\n\n\n\n\n\n\n\n(df_pd.isna().sum() / len(df_pd)) * 100\n\nSALARY                   0.0\nSTATE_NAME               0.0\nNAICS2_NAME              0.0\nEDUCATION_LEVELS_NAME    0.0\nMIN_YEARS_EXPERIENCE     0.0\nDURATION                 0.0\ndtype: float64"
  },
  {
    "objectID": "assignment04-tluck15.html#load-data-and-review",
    "href": "assignment04-tluck15.html#load-data-and-review",
    "title": "Assignment 04",
    "section": "",
    "text": "np.random.seed(42)\n\npio.renderers.default = \"notebook+notebook_connected+vscode\"\n\n# Initialize Spark Session\nspark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n\n# Load Data\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"data/lightcast_job_postings.csv\")\n\n# Show Schema and Sample Data\n#print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n\n#df.printSchema() # comment this line when rendering the submission\ndf.show(5)\n\nWARNING: Using incubator modules: jdk.incubator.vector\nUsing Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/10/17 03:34:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n25/10/17 03:34:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n[Stage 1:&gt;                                                          (0 + 1) / 1]                                                                                25/10/17 03:34:30 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n[Stage 2:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\nonly showing top 5 rows\n\n\n\n\n\n\n\n\ndf = df.select(\"SALARY\",\"STATE_NAME\",\"NAICS2_NAME\", \"EDUCATION_LEVELS_NAME\", \"MIN_YEARS_EXPERIENCE\", \"DURATION\")\n#df.show()\ndf = df.na.fill({\"MIN_YEARS_EXPERIENCE\": 0, \"DURATION\":0})\n#df.show()\n\n\n\n\n\ndf_pd = df.toPandas()\n#df_pd.head(5)\n(df_pd.isna().sum() / len(df_pd)) * 100\n\n[Stage 3:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\nSALARY                   57.505035\nSTATE_NAME                0.060691\nNAICS2_NAME               0.060691\nEDUCATION_LEVELS_NAME     0.060691\nMIN_YEARS_EXPERIENCE      0.000000\nDURATION                  0.000000\ndtype: float64\n\n\n\n\n\n\nsns.heatmap(df_pd.isna(), cbar=False)\nplt.title(\"Missing Data Heatmap\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\ndf = df.na.drop(subset=[\"SALARY\"])\ndf_pd = df.toPandas()\n\nsns.heatmap(df_pd.isna(), cbar=False)\nplt.title(\"Missing Data Heatmap\")\nplt.show()\n\n[Stage 4:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n\n\n\n\n\n\n\n\n\n\n\n(df_pd.isna().sum() / len(df_pd)) * 100\n\nSALARY                   0.0\nSTATE_NAME               0.0\nNAICS2_NAME              0.0\nEDUCATION_LEVELS_NAME    0.0\nMIN_YEARS_EXPERIENCE     0.0\nDURATION                 0.0\ndtype: float64"
  },
  {
    "objectID": "assignment04-tluck15.html#first-take-the-input-variables-and-split-into-numeric-and-non-numeric-goups.-state-name-education-levels-naics_name-are-all-categoric-variables.-min-years-experience-and-duration-are-numeric.",
    "href": "assignment04-tluck15.html#first-take-the-input-variables-and-split-into-numeric-and-non-numeric-goups.-state-name-education-levels-naics_name-are-all-categoric-variables.-min-years-experience-and-duration-are-numeric.",
    "title": "Assignment 04",
    "section": "2.1 First take the input variables and split into numeric and non numeric goups. State name, education levels, NAICS_NAME are all categoric variables. Min years experience and duration are numeric.",
    "text": "2.1 First take the input variables and split into numeric and non numeric goups. State name, education levels, NAICS_NAME are all categoric variables. Min years experience and duration are numeric.\n\n# Suppose you have these columns\ncategorical_cols = [\"STATE_NAME\", \"EDUCATION_LEVELS_NAME\",\"NAICS2_NAME\"]\nnumeric_cols = [\"MIN_YEARS_EXPERIENCE\", \"DURATION\"]\n\n\n2.1.1 For the categorical columns, assign index values to each column and then one hot encode the columns as a vector.\n\nindexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\") for col in categorical_cols]\nencoders = [OneHotEncoder(inputCols=[f\"{col}_indexed\"], outputCols=[f\"{col}_encoded\"]) for col in categorical_cols]\n\n\n\n2.1.2 Next compile the one hot encoded columns with the numeric columns in a vector to be used in feature modeling.\n\nassembler_inputs = [f\"{col}_encoded\" for col in categorical_cols] + numeric_cols\nassembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n\n\n\n2.1.3 Store these data preparation steps as a pipeline for further use\n\npipeline = Pipeline(stages=indexers + encoders + [assembler])\n\n\n\n2.1.4 For polynomial square min years experience\n\nfrom pyspark.sql.functions import col, pow\n\ndf_poly = df.withColumn(\"MIN_YEARS_EXPERIENCE_SQ\", pow(col(\"MIN_YEARS_EXPERIENCE\"), 2))\n\n\n\n2.1.5 Assemble vector using min years and min years experience for polynomial features.\n\nfrom pyspark.ml.feature import VectorAssembler\n\nassembler_poly = VectorAssembler(\n    inputCols=[\"MIN_YEARS_EXPERIENCE\", \"MIN_YEARS_EXPERIENCE_SQ\"],\n    outputCol=\"features_poly\"\n)\n\ndf_poly = assembler_poly.transform(df_poly)\n\n\ndf_poly.printSchema()\n\nroot\n |-- SALARY: integer (nullable = true)\n |-- STATE_NAME: string (nullable = true)\n |-- NAICS2_NAME: string (nullable = true)\n |-- EDUCATION_LEVELS_NAME: string (nullable = true)\n |-- MIN_YEARS_EXPERIENCE: integer (nullable = false)\n |-- DURATION: integer (nullable = false)\n |-- MIN_YEARS_EXPERIENCE_SQ: double (nullable = false)\n |-- features_poly: vector (nullable = true)\n\n\n\n\n#df_poly.show()\n\n\n\n2.1.6 Now split the data for training and testing in a 70/30% split.\n\ntrain_df, test_df = df.randomSplit([0.7, 0.3], seed=42)\n\n\n\n2.1.7 Use the previusly created pipeline the prepare the training and test data for use.\n\npipeline_model = pipeline.fit(train_df)\ntrain_ready = pipeline_model.transform(train_df)\ntest_ready = pipeline_model.transform(test_df)\n\n[Stage 5:&gt;                                                          (0 + 1) / 1]                                                                                [Stage 11:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 17:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\n\n\n2.1.8 Parse target variable and features vector for modeling.\n\ntrain_ready = train_ready[\"SALARY\",\"features\"]\n#train_ready.show()\n\ntest_ready = test_ready[\"SALARY\",\"features\"]\n\n\n\n2.1.9 Confirm schema for linear regression model.\n\ntrain_ready.printSchema()\n\nroot\n |-- SALARY: integer (nullable = true)\n |-- features: vector (nullable = true)"
  },
  {
    "objectID": "assignment04-tluck15.html#build-and-fit-model",
    "href": "assignment04-tluck15.html#build-and-fit-model",
    "title": "Assignment 04",
    "section": "3.1 Build and fit model",
    "text": "3.1 Build and fit model\n\n3.1.1 Penalalize large coefficients and keep all features. Allow for intercept and standardize the data accross variables.\n\nlrm = LinearRegression(\n  featuresCol=\"features\",\n  labelCol=\"SALARY\",\n  predictionCol=\"prediction\",\n  maxIter=100,\n  regParam=0.1,\n  elasticNetParam=0.0,\n  fitIntercept=True,\n  standardization=True,\n)\n\nmodelLR = lrm.fit(train_ready)\n\n[Stage 23:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 24:&gt;                                                         (0 + 1) / 1]"
  },
  {
    "objectID": "assignment04-tluck15.html#linear-regression-model-summary-on-train-and-test-data",
    "href": "assignment04-tluck15.html#linear-regression-model-summary-on-train-and-test-data",
    "title": "Assignment 04",
    "section": "3.2 Linear Regression Model Summary on Train and test data",
    "text": "3.2 Linear Regression Model Summary on Train and test data\n\nsummary = modelLR.summary\n\n\n3.2.1 Issue existed with spillover so control with se, tvals, pvals. For features, loop through for only the number of coefficients so to avoid spillover.\n\n\n3.2.2 Linear regression model performed well. All features had statistically significant p values, moderately large t values, reasonably equivalent coefficient magnitudes with respect to salary, which is reflected in the stndard error being significantly smaller than the respective coefficient.\n\nse = summary.coefficientStandardErrors[1:]\ntvals = summary.tValues[1:]\npvals = summary.pValues[1:]\n\ncoef_df = pd.DataFrame({\n    \"Feature\": [f\"feature_{i+1}\" for i in range(len(modelLR.coefficients))],\n    \"Coefficient\": modelLR.coefficients.toArray(),\n    \"StdError\": se,\n    \"tValue\": tvals,\n    \"pValue\": pvals\n})\n\ncoef_df.head(100)\n\n\n\n\n\n\n\n\nFeature\nCoefficient\nStdError\ntValue\npValue\n\n\n\n\n0\nfeature_1\n27160.771987\n5586.524673\n3.197485\n1.388322e-03\n\n\n1\nfeature_2\n17862.826140\n5604.708248\n3.970201\n7.204534e-05\n\n\n2\nfeature_3\n22251.815915\n5628.321573\n2.900919\n3.724464e-03\n\n\n3\nfeature_4\n16327.306545\n5639.799141\n3.565083\n3.645294e-04\n\n\n4\nfeature_5\n20106.349447\n5650.125035\n3.825928\n1.306483e-04\n\n\n...\n...\n...\n...\n...\n...\n\n\n93\nfeature_94\n-13950.827368\n9974.182772\n-0.376460\n7.065783e-01\n\n\n94\nfeature_95\n-3754.885150\n10060.013381\n0.278668\n7.805023e-01\n\n\n95\nfeature_96\n2803.403880\n73.807420\n74.588198\n0.000000e+00\n\n\n96\nfeature_97\n5505.162463\n15.692949\n-6.188578\n6.180532e-10\n\n\n97\nfeature_98\n-97.117036\n36792.595281\n0.164635\n8.692328e-01\n\n\n\n\n98 rows  5 columns"
  },
  {
    "objectID": "assignment04-tluck15.html#now-validate-and-run-the-model-using-the-test-data",
    "href": "assignment04-tluck15.html#now-validate-and-run-the-model-using-the-test-data",
    "title": "Assignment 04",
    "section": "3.3 Now validate and run the model using the test data",
    "text": "3.3 Now validate and run the model using the test data\n\ntestmodelLR = lrm.fit(test_ready)\n\n[Stage 25:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 26:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\n\ntestsummary = testmodelLR.summary\n\nt_values = summary.tValues\np_values = summary.pValues\n\nstats_df = pd.DataFrame({\n    \"t_value\": t_values,\n    \"p_value\": p_values\n})\n\ndesc_stats = stats_df.describe()\nprint(desc_stats)\n\n         t_value    p_value\ncount  99.000000  99.000000\nmean    2.496936   0.176394\nstd     7.503150   0.265126\nmin    -6.188578   0.000000\n25%     0.898590   0.003787\n50%     2.039629   0.036848\n75%     2.887619   0.279912\nmax    74.588198   0.981592\n\n\n\n3.3.1 Issue existed with spillover so control with se, tvals, pvals. For features, loop through for only the number of coefficients so to avoid spillover.\n\n\n3.3.2 The linear regression model performed okay on the test data. Accross the 99 features, the average p value was not significant, however the median value was significant at appx. .037 - the 75th percentile is not significant but the 25th is. THere were a few features that produced extreme results in all of the t value (~-6/74), p value (0/.98), and coefficient (a few spikes). R squared states ~35% of variation in salary can be explained by the features in the data. On average predictions are off by ~$35,834.\n\nse = testsummary.coefficientStandardErrors[1:]\ntvals = testsummary.tValues[1:]\npvals = testsummary.pValues[1:]\n\ntestcoef_df = pd.DataFrame({\n    \"Feature\": [f\"feature_{i+1}\" for i in range(len(testmodelLR.coefficients))],\n    \"Coefficient\": testmodelLR.coefficients.toArray(),\n    \"StdError\": se,\n    \"tValue\": tvals,\n    \"pValue\": pvals\n})\n\nprint(\"R2:\", testsummary.r2)\nprint(\"RMSE:\", testsummary.rootMeanSquaredError)\n\n#coef_df.head(100)\n# Scale coefficients to t-values range\ntestcoef_df[\"Coefficient_log\"] = np.log(np.abs(testcoef_df[\"Coefficient\"]) + 1e-8) \n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,6))\n\n# x-axis = features\nx = testcoef_df[\"Feature\"]\n\n# plot each statistic as a line\nplt.plot(x, testcoef_df[\"Coefficient_log\"], marker='o', label=\"Coefficient Scaled\")\nplt.plot(x, testcoef_df[\"tValue\"], marker='s', label=\"t-value\")\nplt.plot(x, testcoef_df[\"pValue\"], marker='^', label=\"p-value\")\n\nplt.axhline(y=2, color='red', linestyle=':', label='t-value threshold')\n\nplt.xticks(rotation=45, ha='right')  # rotate feature names for readability\nplt.xlabel(\"Features\")\nplt.ylabel(\"Values\")\nplt.title(\"Model Summary: Coefficients, t-values, p-values\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nR2: 0.35636023407578243\nRMSE: 35834.08039301742"
  },
  {
    "objectID": "assignment04-tluck15.html#combine-numeric-and-non-numeric-columns.",
    "href": "assignment04-tluck15.html#combine-numeric-and-non-numeric-columns.",
    "title": "Assignment 04",
    "section": "4.1 Combine numeric and non numeric columns.",
    "text": "4.1 Combine numeric and non numeric columns.\n\nassembler_poly = VectorAssembler(\n    inputCols=[\"MIN_YEARS_EXPERIENCE\", \"DURATION\"],\n    outputCol=\"numeric_features\"\n)\n\n#expand to polynomial\npoly_expansion = PolynomialExpansion(\n    degree=2, \n    inputCol=\"numeric_features\", \n    outputCol=\"poly_features\"\n)\n\n\n4.1.1 Use the pipeline created earlier to prepare the polynomial features.\n\nassembler_final = VectorAssembler(\n    inputCols=[\"poly_features\"] + [f\"{col}_encoded\" for col in categorical_cols],\n    outputCol=\"features\"\n)\n\npoly_pipeline = Pipeline(stages=indexers + encoders + [assembler_poly, poly_expansion, assembler_final])\n\n\n\n4.1.2 Fit model and apply same parameters as the linear regression. ~36.8% of variation in salary can be explained by the feature variables. And on average the prediction was off by $36,025.\n\npoly_model = poly_pipeline.fit(train_df)\ntrain_poly = poly_model.transform(train_df)\ntest_poly = poly_model.transform(test_df)\n\nlrm_poly = LinearRegression(\n    featuresCol=\"features\",\n    labelCol=\"SALARY\",\n    predictionCol=\"prediction\",\n    maxIter=100,\n    regParam=0.1,\n    elasticNetParam=0.0\n)\n\nmodel_poly = lrm_poly.fit(train_poly)\nsummary_poly = model_poly.summary\n\nprint(\"R2:\", summary_poly.r2)\nprint(\"RMSE:\", summary_poly.rootMeanSquaredError)\n\n[Stage 27:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 33:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 39:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 45:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 46:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 47:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 48:&gt;                                                         (0 + 1) / 1]\n\n\nR2: 0.36831696100365496\nRMSE: 36025.51327867095\n\n\n                                                                                \n\n\n\nse = summary_poly.coefficientStandardErrors[1:]\ntvals = summary_poly.tValues[1:]\npvals = summary_poly.pValues[1:]\n\ncoef_df = pd.DataFrame({\n    \"Feature\": [f\"feature_{i+1}\" for i in range(len(model_poly.coefficients))],\n    \"Coefficient\": model_poly.coefficients.toArray(),\n    \"StdError\": se,\n    \"tValue\": tvals,\n    \"pValue\": pvals\n})\n\ncoef_df.head()\n\n\n\n\n\n\n\n\nFeature\nCoefficient\nStdError\ntValue\npValue\n\n\n\n\n0\nfeature_1\n4534.036373\n16.938884\n5.113944\n3.182049e-07\n\n\n1\nfeature_2\n86.624507\n49.042361\n-8.224292\n2.220446e-16\n\n\n2\nfeature_3\n-403.338710\n4.098090\n0.271263\n7.861914e-01\n\n\n3\nfeature_4\n1.111660\n0.982271\n6.941764\n3.982370e-12\n\n\n4\nfeature_5\n6.818695\n5553.886969\n4.923227\n8.575835e-07\n\n\n\n\n\n\n\n\n\n4.1.3 Overall the polynomial model performed worse than the linear regression model. All of the p value, t value, and coefficients experience high volatilitity and varying results.\n\n# Scale coefficients with log\ncoef_df[\"Coefficient_log\"] = np.log(np.abs(coef_df[\"Coefficient\"]) + 1e-8) \n\nplt.figure(figsize=(12,6))\n\n# x-axis = features\nx = coef_df[\"Feature\"]\n\n# plot each statistic as a line\nplt.plot(x, coef_df[\"Coefficient_log\"], marker='o', label=\"Coefficient Scaled\")\nplt.plot(x, coef_df[\"tValue\"], marker='s', label=\"t-value\")\nplt.plot(x, coef_df[\"pValue\"], marker='^', label=\"p-value\")\n\nplt.axhline(y=2, color='red', linestyle=':', label='t-value threshold')\n\nplt.xticks(rotation=45, ha='right')  # rotate feature names for readability\nplt.xlabel(\"Features\")\nplt.ylabel(\"Values\")\nplt.title(\"Model Summary: Coefficients, t-values, p-values\")\nplt.legend()\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "assignment04-tluck15.html#setup-model",
    "href": "assignment04-tluck15.html#setup-model",
    "title": "Assignment 04",
    "section": "5.1 Setup model",
    "text": "5.1 Setup model\n\n5.1.1 100 trees, 10 levels of depth to each branch, max of 18 bins for feature categorization.\n\nfrom pyspark.ml.regression import RandomForestRegressor\n\nrf = RandomForestRegressor(\n    labelCol=\"SALARY\",\n    featuresCol=\"features\",\n    numTrees=100,           # number of trees (more trees = more stability)\n    maxDepth=10,            # depth of each tree\n    maxBins=18,             # controls how continuous features are binned\n    seed=42\n)\n\n\n\n5.1.2 Like the other models, assemble the data and prepare it using the pipeline setup earlier in the project.\n\nrf_pipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n\n\n\n5.1.3 Train and then make predictions on test data. [stopping point]\n\nrf_model = rf_pipeline.fit(train_df)\npredictions = rf_model.transform(test_df)\n\n[Stage 49:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 55:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 61:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 67:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 68:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 69:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 71:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 73:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 75:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 77:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 79:&gt;                                                         (0 + 1) / 1]                                                                                25/10/17 03:36:57 WARN DAGScheduler: Broadcasting large task binary with size 1319.0 KiB\n[Stage 81:&gt;                                                         (0 + 1) / 1]                                                                                25/10/17 03:36:59 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n[Stage 83:&gt;                                                         (0 + 1) / 1]                                                                                25/10/17 03:37:03 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n[Stage 85:&gt;                                                         (0 + 1) / 1][Stage 86:&gt;                                                         (0 + 1) / 1]                                                                                25/10/17 03:37:07 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n[Stage 87:&gt;                                                         (0 + 1) / 1][Stage 88:&gt;                                                         (0 + 1) / 1]                                                                                25/10/17 03:37:11 WARN DAGScheduler: Broadcasting large task binary with size 7.4 MiB\n[Stage 89:&gt;                                                         (0 + 1) / 1][Stage 90:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\n\nevaluator = RegressionEvaluator(\n    labelCol=\"SALARY\",\n    predictionCol=\"prediction\",\n    metricName=\"r2\"\n)\n\nr2 = evaluator.evaluate(predictions)\nrmse = RegressionEvaluator(\n    labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"rmse\"\n).evaluate(predictions)\n\nmae = RegressionEvaluator(\n    labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"mae\"\n).evaluate(predictions)\n\nprint(f\"R: {r2:.3f}\")\nprint(f\"RMSE: {rmse:.3f}\")\nprint(f\"MAE: {mae:.3f}\")\n\n[Stage 91:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 92:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 93:&gt;                                                         (0 + 1) / 1]\n\n\nR: 0.429\nRMSE: 33744.372\nMAE: 25175.654\n\n\n                                                                                \n\n\n\nrf_stage = rf_model.stages[-1] \n\nimportances = rf_stage.featureImportances.toArray()\n\nfeat_imp = pd.DataFrame({\n    \"Feature\": [f\"feature_{i+1}\" for i in range(len(importances))],\n    \"Importance\": importances\n}).sort_values(by=\"Importance\", ascending=False)\n\nfeat_imp.head(10)\n\n\n\n\n\n\n\n\nFeature\nImportance\n\n\n\n\n96\nfeature_97\n0.521858\n\n\n54\nfeature_55\n0.083882\n\n\n76\nfeature_77\n0.069038\n\n\n80\nfeature_81\n0.045592\n\n\n97\nfeature_98\n0.031267\n\n\n55\nfeature_56\n0.029943\n\n\n83\nfeature_84\n0.025972\n\n\n52\nfeature_53\n0.016110\n\n\n77\nfeature_78\n0.013780\n\n\n51\nfeature_52\n0.013470\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10,6))\nsns.barplot(data=feat_imp.head(15), y=\"Feature\", x=\"Importance\", palette=\"viridis\")\nplt.title(\"Top 15 Random Forest Feature Importances\")\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_8037/3261347940.py:5: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect."
  }
]